
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Lossy Compression and Learning &#8212; Dan Jacobellis | University of Texas at Austin</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Compressed Learning" href="milestone.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="lossy-compression-and-learning">
<h1>Lossy Compression and Learning<a class="headerlink" href="#lossy-compression-and-learning" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://danjacobellis.github.io/ITML/lossy_learning.slides.html">Slides</a></p>
<section id="conventional-approach">
<h2>Conventional approach<a class="headerlink" href="#conventional-approach" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Consider a classification problem</p>
<ul>
<li><p>Lossy compressed data (MP3, JPEG): 1-4 bits per sample</p></li>
<li><p>Decoded data: 8-16 bits per sample</p></li>
<li><p>Floating point for training: 32 bits per sample</p></li>
</ul>
</li>
<li><p>Still suffers from all of the downsides of lossy compression</p></li>
<li><p>Don’t get any of the benefits of smaller representation!</p></li>
</ul>
</section>
<section id="low-precision-floating-point">
<h2>Low precision floating point<a class="headerlink" href="#low-precision-floating-point" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>bfloat16 (standardized in 2018)</p></li>
<li><p>FP8 (E4M3 and E5M2, standardized in 2022)</p></li>
<li><p>Fewer than 8 bits requires radical changes to training procedures</p></li>
<li><p>Still not able to get any benefits of lossy encodings (1-4 bits per sample)</p></li>
</ul>
</section>
<section id="training-on-compressed-data">
<h2>Training on compressed data<a class="headerlink" href="#training-on-compressed-data" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Consider the imagenet datasat consisting of JPEG coded images</p>
<ul>
<li><p>Images are 2-4 bits per pixel after quantization</p></li>
<li><p>about 1.5 bits after entropy coding (RLE and Huffman)</p></li>
</ul>
</li>
</ul>
<p><img alt="" src="_images/lossy_lossless.png" /></p>
</section>
<section id="id1">
<h2>Conventional approach<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Decode image and convert to floating point</p></li>
<li><p>Size of input layer: <span class="math notranslate nohighlight">\(224 \times224 \times 3 \times 32\)</span> bits per image</p></li>
<li><p>For batch size of 128:</p></li>
<li><p>13 GB feature memory</p></li>
<li><p>497 GFLOPs</p></li>
</ul>
</section>
<section id="training-on-encoded-data">
<h2>Training on encoded data<a class="headerlink" href="#training-on-encoded-data" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Conventional approach</p>
<ul>
<li><p>13 GB feature memory</p></li>
<li><p>497 GFLOPs per pass</p></li>
</ul>
</li>
<li><p>Alternative approach</p>
<ul>
<li><p>Each transform coefficient only contains about 2 bits instead of 8</p></li>
<li><p>“Replace” each 2x2 blocks of 2-bit transform coefficients with a single high precision input</p></li>
<li><p>Size of input layer: <span class="math notranslate nohighlight">\(112 \times 112 \times 3 \times 32\)</span> bits per image</p></li>
<li><p>3 GB Feature memory</p></li>
<li><p>131 GFLOPs per pass</p></li>
</ul>
</li>
<li><p>How do we “replace” several low-precision inputs with a single high precision input?</p></li>
<li><p>Doesn’t even work for JPEG since each DCT coefficient has different quantization!</p></li>
</ul>
<p><a class="reference external" href="https://github.com/albanie/convnet-burden/blob/master/reports/resnet-50.md">resnet 50 reference</a></p>
</section>
<section id="id2">
<h2>Training on encoded data<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>How do we “replace” several low-precision inputs with a single high precision input?</p></li>
<li><p>Naive approach: <span class="math notranslate nohighlight">\(y = (x_1) + (x2 &lt;&lt; 2) + (x2 &lt;&lt; 4) (x2 &lt;&lt; 6)\)</span></p>
<ul>
<li><p>Amounts to creating a categorical variable</p></li>
<li><p>Standard approach to training on categorical variable is to one-hot encode</p>
<ul>
<li><p>We’re back to where we started!</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="binarized-neural-networks">
<h2>Binarized neural networks<a class="headerlink" href="#binarized-neural-networks" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Proposed in 2016 to reduce memory consumption</p></li>
<li><p>Replace some floating point arithmetic with bit-wise operations</p>
<ul>
<li><p>Binary Weight Network (BWN): only the kernels are quantized</p></li>
<li><p>Binary Activation Network (BAN): only the inputs are binarized</p></li>
<li><p>Binary Neural Network (BNN): both the inputs as well as the kernels are binarized</p></li>
</ul>
</li>
<li><p>First layer of BNN is typically represented at full precision</p>
<ul>
<li><p>Gives us an opportunity to utilize low precision of lossy coded data</p></li>
</ul>
</li>
</ul>
</section>
<section id="types-of-lossy-compression">
<h2>Types of lossy compression<a class="headerlink" href="#types-of-lossy-compression" title="Permalink to this headline">¶</a></h2>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Standard</p></th>
<th class="head"><p>Introduced</p></th>
<th class="head"><p>Signal</p></th>
<th class="head"><p>Transform</p></th>
<th class="head"><p>Quantization</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MPEG Layer III</p></td>
<td><p>1991</p></td>
<td><p>Audio</p></td>
<td><p>block DCT and FFT</p></td>
<td><p>Perceptual quantization vector</p></td>
</tr>
<tr class="row-odd"><td><p>JPEG</p></td>
<td><p>1992</p></td>
<td><p>Image</p></td>
<td><p>block DCT</p></td>
<td><p>Perceptual quantization matrix</p></td>
</tr>
<tr class="row-even"><td><p>JPEG 2000</p></td>
<td><p>2000</p></td>
<td><p>Image</p></td>
<td><p>Separable Wavelet</p></td>
<td><p>Uniform scalar quantization</p></td>
</tr>
<tr class="row-odd"><td><p>CELT/Opus</p></td>
<td><p>2011</p></td>
<td><p>Audio</p></td>
<td><p>block DCT</p></td>
<td><p>Pyramid vector quantization</p></td>
</tr>
<tr class="row-even"><td><p>HEVC</p></td>
<td><p>2013</p></td>
<td><p>Image</p></td>
<td><p>block DCT and DST</p></td>
<td><p>Perceptual quantization matrix</p></td>
</tr>
<tr class="row-odd"><td><p>Soundstream</p></td>
<td><p>2021</p></td>
<td><p>Audio</p></td>
<td><p>Learned</p></td>
<td><p>Residual vector quantization</p></td>
</tr>
</tbody>
</table>
</section>
<section id="audio-classification-baseline">
<h2>Audio classification: baseline<a class="headerlink" href="#audio-classification-baseline" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Dataset: Speech commands</p>
<ul>
<li><p>one second speech segments of 8 possible words</p></li>
<li><p>‘stop,’ ‘down,’ ‘no,’ ‘right,’ ‘go,’ ‘up,’ ‘yes,’ ‘left’</p></li>
</ul>
</li>
<li><p>Baseline model:</p>
<ul>
<li><p>Input size: <span class="math notranslate nohighlight">\(128 \times 128\)</span> time-frequency distribution represented at full precision</p></li>
<li><p>119.52 MiB Feature size</p></li>
<li><p>2.26 GFLOPs per pass</p></li>
<li><p>Achieves test accuracy of about 84%</p></li>
</ul>
</li>
</ul>
</section>
<section id="audio-classification-bnn-vq">
<h2>Audio classification: BNN + VQ<a class="headerlink" href="#audio-classification-bnn-vq" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Encode 2x2 time-frequency blocks via vector quantization</p>
<ul>
<li><p>Use mini-batch k-means to learn codebook of 16 vectors (4 bits)</p></li>
<li><p>Compression ratio of 16:1 (before any entropy coding)</p></li>
</ul>
</li>
<li><p>Input size: <span class="math notranslate nohighlight">\(64 \times 64 \times 4\)</span> binary codes</p></li>
<li><p>3.74 MiB Feature size</p></li>
<li><p>Multiply-accumulate instead of FP</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(4-8 \times\)</span> more power efficient compared to bfloat16</p></li>
<li><p><span class="math notranslate nohighlight">\(&gt;20 \times\)</span> more power efficient compared to FP32</p></li>
</ul>
</li>
<li><p>Achieves test accuracy of about 79% (baseline:84%)</p></li>
</ul>
<p><a class="reference external" href="https://proceedings.neurips.cc/paper/2020/file/13b919438259814cd5be8cb45877d577-Paper.pdf">IBM 4-bit</a></p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Information Theory and Machine Learning</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="learning_from_compressed.html">Learning from compressed Audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="discrete_representation_learning.html">Discrete Representation Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestone.html">Compressed Learning</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Lossy Compression and Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#conventional-approach">Conventional approach</a></li>
<li class="toctree-l2"><a class="reference internal" href="#low-precision-floating-point">Low precision floating point</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-on-compressed-data">Training on compressed data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id1">Conventional approach</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-on-encoded-data">Training on encoded data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">Training on encoded data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#binarized-neural-networks">Binarized neural networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#types-of-lossy-compression">Types of lossy compression</a></li>
<li class="toctree-l2"><a class="reference internal" href="#audio-classification-baseline">Audio classification: baseline</a></li>
<li class="toctree-l2"><a class="reference internal" href="#audio-classification-bnn-vq">Audio classification: BNN + VQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="milestone.html" title="previous chapter">Compressed Learning</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.5.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/lossy_learning.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>