{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267e4f8c-85dd-4f36-9ee4-0462952afe5d",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "# Discrete Representation Learning\n",
    "\n",
    "[Paper](https://proceedings.neurips.cc/paper/2017/hash/7a98af17e63a0ac09ce2e96d03992fbc-Abstract.html)\n",
    "\n",
    "[Slides](https://danjacobellis.github.io/ITML/discrete_representation_learning.slides.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e072a5-d669-4465-9a53-03cf7f807acd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<script>\n",
    "    document.querySelector('head').innerHTML += '<style>.slides { zoom: 1.75 !important; }</style>';\n",
    "</script>\n",
    "\n",
    "<center> <h1>\n",
    "Discrete Representation Learning\n",
    "</h1> </center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center> <h3>\n",
    "Dan Jacobellis\n",
    "</h3> </center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\\[1\\] [Neural discrete representation learning.](https://proceedings.neurips.cc/paper/2017/hash/7a98af17e63a0ac09ce2e96d03992fbc-Abstract.html) Van Den Oord et al. NIPS 2017.\n",
    "\n",
    "\\[2\\] [Jukebox: A Generative Model for Music.](https://openai.com/blog/jukebox/) Dhariwal et al. OpenAI 2020.\n",
    "\n",
    "\\[3\\] [Zero-Shot Text-to-Image Generation.](http://proceedings.mlr.press/v139/ramesh21a.html?ref=https://githubhelp.com) Ramesh et al. PMLR 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6563e94b-b7ea-4dd1-9541-9b9ec85ad061",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Vector Quantization\n",
    "\n",
    "* Suppose we have a randomly sampled vector $x$ from some distribution.\n",
    "  * Example: $x$ is a digital audio recording, image, or video.\n",
    "* Goal: create a codebook of $k$ vectors $c_k$ so that $x$ is close to at least one of the vectors in the codebook.\n",
    "\n",
    "$$k^* = \\text{arg} \\min_{k}{\\lVert x-c_k\\rVert ^2}$$\n",
    "\n",
    "$$x \\approx c_{k^*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56dbb52-3a89-43aa-9052-198d65ae1a33",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/vq.png\" width=300 height=300 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14b23a-abc0-4139-a777-9d7d86db5396",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/vq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c900c-b80f-4c7a-9fcf-d19c74b18b19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Vector Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb587588-c9e7-439b-9fae-7ca96469f2b8",
   "metadata": {},
   "source": [
    "* Simple and effective form of lossy compression\n",
    "* Still used today for high quality audio compression\n",
    "* How to find the codebook?\n",
    "\n",
    "$$\\{c_k^*\\} := \\arg\\min_{\\{c_k\\}} \\sum_{h=1}^N \\min_k\n",
    "\\|x_h-c_k\\|^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06d13f7-952e-490a-8cc5-282cd4e8a4df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Variational Autoencoders\n",
    "\n",
    "* Encoder parameterises a posterior $q(z|x)$\n",
    "* Decoder's distribution over input data is $p(x|z)$\n",
    "* Prior distribution $p(z)$ is Gaussain with diagonal covariance\n",
    "  * Allows us to take advantage of reparameterization trick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97399eda-6cdd-4026-be6a-33669e16d5da",
   "metadata": {},
   "source": [
    "## Vector-quantized autoencoder\n",
    "\n",
    "* Discrete prior instead of Gaussian\n",
    "* Latent embedding space consists of codebook: $e\\in R^{K\\times D}$\n",
    "* Posterior $q(z|x)$ is a set of codes\n",
    "  \n",
    "![](img/vqvae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be1271-a41b-4a3c-8934-668413f89c00",
   "metadata": {},
   "source": [
    "## Discrete latent variables\n",
    "\n",
    "* Output of encoder is $z_e(x)$\n",
    "* Nearest neighbor look-up in the embedding space $e$\n",
    "\n",
    "$$k=\\text{arg}\\min_{j}{\\lVert z_e(x) - e_j \\rVert_2}$$\n",
    "\n",
    "$$q(z|x)=\\begin{cases}1 & \\text{for } z=k \\\\ 0 & \\text{otherwise} \\end{cases}$$\n",
    "\n",
    "$$z_q(x)=e_k$$\n",
    "  \n",
    "![](img/encoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc93de-dbe9-41ec-98c2-a8c2baa1a614",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "* Input to decoder is the embedding vector $e_k$\n",
    "\n",
    "![](decoder.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
